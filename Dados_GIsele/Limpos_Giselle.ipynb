{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Limpar aquivos 1k, 5k, 100k</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analisar estrutura de um tweet</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>contributors</th>\n",
       "      <th>truncated</th>\n",
       "      <th>text</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>id</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>place</th>\n",
       "      <th>control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$numberLong': '1240986591545393153'}</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Covid-19: quem vai colher os erros de Bolsonar...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'$numberLong': '1240986591545393153'}</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'display_text_range': [0, 223], 'entities': {...</td>\n",
       "      <td>{'$date': '2020-03-19T10:00:34.000-0300'}</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'coleta': [439]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id  quote_count  contributors  \\\n",
       "0  {'$numberLong': '1240986591545393153'}            0           NaN   \n",
       "\n",
       "   truncated                                               text  \\\n",
       "0       True  Covid-19: quem vai colher os erros de Bolsonar...   \n",
       "\n",
       "   is_quote_status  in_reply_to_status_id  reply_count  \\\n",
       "0            False                    NaN            0   \n",
       "\n",
       "                                       id  favorite_count  ... geo  \\\n",
       "0  {'$numberLong': '1240986591545393153'}               0  ... NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  possibly_sensitive  lang  \\\n",
       "0                      NaN               False    pt   \n",
       "\n",
       "                                      extended_tweet  \\\n",
       "0  {'display_text_range': [0, 223], 'entities': {...   \n",
       "\n",
       "                                  created_at  filter_level  \\\n",
       "0  {'$date': '2020-03-19T10:00:34.000-0300'}           low   \n",
       "\n",
       "  in_reply_to_status_id_str  place            control  \n",
       "0                       NaN    NaN  {'coleta': [439]}  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tab_1 = pd.read_json('1_tweet.json',lines=True,convert_dates=False)\n",
    "tab_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'follow_request_sent': None, 'profile_use_bac...\n",
       "Name: user, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_1['user']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Criar arquivo com tweets por usuário por dia</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "#stopwords em portugues\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('portuguese') + list(punctuation) + ['“','”'])\n",
    "\n",
    "#funçao pra limpeza de texto\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra leitura de dados e criaçao de dataframe\n",
    "def json_to_dataframe(nome_json, colunas, chunk=30):\n",
    "    dados = pd.read_json(nome_json, convert_dates = False, lines = True, chunksize = chunk)    \n",
    "    \n",
    "    for df_tweets_retweets in dados:\n",
    "        yield df_tweets_retweets[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra limpar texto e retirar stopwords\n",
    "def tokenizar_texto(texto_tweet):\n",
    "    texto_tokenizado = tweet_tokenizer.tokenize(texto_tweet)\n",
    "\n",
    "    if texto_tokenizado[0] == \"rt\" and texto_tokenizado[1] == \":\":\n",
    "        del texto_tokenizado[0]\n",
    "    \n",
    "    palavras_sem_stopwords = [palavra for palavra in texto_tokenizado if palavra not in stopwords] \n",
    "    return palavras_sem_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra criar dicionario com a data e quantidade dos tweets por usuario\n",
    "def contagem_usuarios_data(gerador,destino):\n",
    "    \n",
    "    dict_datas_usuarios = defaultdict(dict)            \n",
    "    \n",
    "    for dataframe in gerador:        \n",
    "        for linha in dataframe.values:            \n",
    "            usuario = linha[0]['screen_name']\n",
    "\n",
    "            data = linha[1]['$date'][:10]\n",
    "            if data not in dict_datas_usuarios or usuario not in dict_datas_usuarios[data]:\n",
    "                dict_datas_usuarios[data][usuario] = 0\n",
    "            dict_datas_usuarios[data][usuario] += 1\n",
    "            clear_output()\n",
    "            \n",
    "    escrever_arq_csv(dict_datas_usuarios,destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra escrever os resultados no arquivo csv\n",
    "def escrever_arq_csv(dict_datas_usuarios,destino):\n",
    "    with open(destino, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(\"Datas;Usuários;Tweets\\n\")\n",
    "\n",
    "        for key in dict_datas_usuarios.keys():\n",
    "            for user in dict_datas_usuarios[key].keys():\n",
    "                f.write(\"%s;%s;%s\\n\"%(key, user, dict_datas_usuarios[key][user]))\n",
    "            \n",
    "    print('A contagem de tweets por usuario por data foi salva com sucesso no arquivo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A contagem de tweets por usuario por data foi salva com sucesso no arquivo\n"
     ]
    }
   ],
   "source": [
    "#execuçao do codigo\n",
    "#1k\n",
    "gerador = json_to_dataframe('1k_origin.json',[\"user\",\"created_at\"])\n",
    "\n",
    "contagem_usuarios_data(gerador,'cont_usuarios_data_1k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A contagem de tweets por usuario por data foi salva com sucesso no arquivo\n"
     ]
    }
   ],
   "source": [
    "#5k\n",
    "gerador = json_to_dataframe('5k_origin.json',[\"user\",\"created_at\"])\n",
    "\n",
    "contagem_usuarios_data(gerador,'cont_usuarios_data_5k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A contagem de tweets por usuario por data foi salva com sucesso no arquivo\n"
     ]
    }
   ],
   "source": [
    "#100k\n",
    "gerador = json_to_dataframe('100k_origin.json',[\"user\",\"created_at\"])\n",
    "\n",
    "contagem_usuarios_data(gerador,'cont_usuarios_data_100k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Fazer análises com arquivo gerado</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Resultar análise do número de usuarios</h3>\n",
    "<p>(Exibir analises em forma gráfica para cada arquivo)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Resultar análise do número de tweets/usuário</h3>\n",
    "<p>(Exibir analises em forma gráfica para cada arquivo)</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
