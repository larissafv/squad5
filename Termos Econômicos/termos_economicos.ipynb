{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "#stopwords em portugues\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('portuguese') + list(punctuation) + ['“','”'])\n",
    "\n",
    "#funçao pra limpeza de texto\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra leitura de dados e criaçao de dataframe\n",
    "def json_to_dataframe(nome_json, colunas, chunk):\n",
    "    dados = pd.read_json(nome_json, convert_dates = False, lines = True, chunksize = chunk)    \n",
    "    \n",
    "    for tweets_retweets in dados:\n",
    "        yield tweets_retweets[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra limpar texto e retirar stopwords\n",
    "def tokenizar_texto(texto_tweet):\n",
    "    texto_tokenizado = tweet_tokenizer.tokenize(texto_tweet)\n",
    "\n",
    "    if texto_tokenizado[0] == \"rt\" and texto_tokenizado[1] == \":\":\n",
    "        del texto_tokenizado[0]\n",
    "    \n",
    "    palavras_sem_stopwords = [palavra for palavra in texto_tokenizado if palavra not in stopwords] \n",
    "    return palavras_sem_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra criar dicionario com a data e quantidade dos termos\n",
    "def contagem_termos_data(termos_lista, gerador):\n",
    "    \n",
    "    dict_datas_termos = defaultdict(dict)\n",
    "    contador = 0\n",
    "    \n",
    "    for dataframe in gerador:        \n",
    "        for linha in dataframe.values:            \n",
    "            texto_tweet = list(tokenizar_texto(linha[0]))\n",
    "\n",
    "            for termo in texto_tweet:                \n",
    "                if termo in termos_lista:\n",
    "                    data = linha[1]['$date'][:10]\n",
    "                    if data not in dict_datas_termos or termo not in dict_datas_termos[data]:\n",
    "                        dict_datas_termos[data][termo] = 0\n",
    "                    dict_datas_termos[data][termo] += 1\n",
    "            clear_output()\n",
    "            contador += 1        \n",
    "            print(\"%s tweets processados\" %(contador))            \n",
    "            print(dict(dict_datas_termos))\n",
    "            \n",
    "    escrever_arq_csv(dict_datas_termos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funçao pra escrever os resultados no arquivo csv\n",
    "def escrever_arq_csv(dict_datas_termos):\n",
    "    with open('termos_economicos_100k.csv', 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(\"Data;Termo;Frequencia\\n\")\n",
    "\n",
    "        for key in dict_datas_termos.keys():\n",
    "            for termo in dict_datas_termos[key].keys():\n",
    "                f.write(\"%s;%s;%s\\n\"%(key, termo, dict_datas_termos[key][termo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 tweets processados\n",
      "{'2020-03-20': {'demissão': 3, 'demitida': 38, 'doação': 82, 'desempregado': 8, 'mei': 6, 'desemprego': 5, 'incerteza': 5, 'bico': 4, 'desempregada': 14, 'demitido': 2, 'informalidade': 1}}\n"
     ]
    }
   ],
   "source": [
    "#execuçao do codigo\n",
    "gerador = json_to_dataframe('100k_origin.json',[\"text\",\"created_at\"], 30)\n",
    "\n",
    "contagem_termos_data(['incerteza', 'desemprego', 'desempregado', 'desempregada', 'demissão', 'demitido', 'demitida',\n",
    "                      'auxilio emergencial', 'mei', 'doação', 'informalidade', 'bico', 'camelô'], gerador)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
